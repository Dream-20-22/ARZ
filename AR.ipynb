{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dream-20-22/ARZ/blob/main/AR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI2H1WRT6zNc"
      },
      "source": [
        "# Arabic Wikipedia with Wikipedia2Vec:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0oD2s1f6oU1",
        "outputId": "14cc539d-10b3-4a61-bc8e-f8fbdb717778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wikipedia2vec\n",
            "  Downloading wikipedia2vec-1.0.5.tar.gz (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from wikipedia2vec) (7.1.2)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from wikipedia2vec) (0.42.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from wikipedia2vec) (1.2.0)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from wikipedia2vec) (0.99)\n",
            "Collecting marisa-trie\n",
            "  Downloading marisa_trie-0.7.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 31.6 MB/s \n",
            "\u001b[?25hCollecting mwparserfromhell\n",
            "  Downloading mwparserfromhell-0.6.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 60.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from wikipedia2vec) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from wikipedia2vec) (1.7.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from wikipedia2vec) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from wikipedia2vec) (4.64.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from marisa-trie->wikipedia2vec) (57.4.0)\n",
            "Building wheels for collected packages: wikipedia2vec\n",
            "  Building wheel for wikipedia2vec (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 350, in run\n",
            "    global_options=[],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/wheel_builder.py\", line 337, in build\n",
            "    req, cache_dir, verify, build_options, global_options\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/wheel_builder.py\", line 224, in _build_one\n",
            "    req, output_dir, build_options, global_options\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/wheel_builder.py\", line 268, in _build_one_inside_env\n",
            "    tempd=temp_dir.path,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 95, in build_wheel_legacy\n",
            "    spinner=spinner,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/subprocess.py\", line 194, in call_subprocess\n",
            "    line = proc.stdout.readline()  # type: str\n",
            "  File \"/usr/lib/python3.7/codecs.py\", line 319, in decode\n",
            "    def decode(self, input, final=False):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/main.py\", line 71, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 104, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 212, in _main\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1425, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1502, in _log\n",
            "    fn, lno, func, sinfo = self.findCaller(stack_info)\n",
            "  File \"/usr/lib/python3.7/logging/__init__.py\", line 1459, in findCaller\n",
            "    filename = os.path.normcase(co.co_filename)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jflq4J1A7HBm"
      },
      "source": [
        "## Downloading Arabic Wikipedia: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlZi2sb47Rll",
        "outputId": "5eaf63dd-6a91-44fc-933c-4d555824dcf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-10-31 19:32:51--  https://dumps.wikimedia.org/arwiki/20220801/arwiki-20220801-pages-articles-multistream.xml.bz2\n",
            "Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 208.80.154.142, 2620:0:861:2:208:80:154:142\n",
            "Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|208.80.154.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1562473861 (1.5G) [application/octet-stream]\n",
            "Saving to: ‘arwiki-20220801-pages-articles-multistream.xml.bz2’\n",
            "\n",
            "arwiki-20220801-pag 100%[===================>]   1.46G  4.58MB/s    in 5m 31s  \n",
            "\n",
            "2022-10-31 19:38:22 (4.50 MB/s) - ‘arwiki-20220801-pages-articles-multistream.xml.bz2’ saved [1562473861/1562473861]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dumps.wikimedia.org/arwiki/20220801/arwiki-20220801-pages-articles-multistream.xml.bz2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLIFE1ZO82ZY"
      },
      "source": [
        "## Training on Arabic Wikipedia with Wikipedia2Vec:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf4PvvtJ8-fH",
        "outputId": "9c99fe79-f42f-43c2-d75e-5cb768ce16e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2022-10-31 19:38:27,552] [INFO] Starting to build a Dump DB... (train@cli.py:128)\n",
            "[2022-10-31 19:43:49,474] [INFO] Processed: 100000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 19:47:09,116] [INFO] Processed: 200000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 19:49:42,577] [INFO] Processed: 300000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 19:52:48,580] [INFO] Processed: 400000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 19:56:03,205] [INFO] Processed: 500000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 19:58:50,341] [INFO] Processed: 600000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:00:56,100] [INFO] Processed: 700000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:02:54,866] [INFO] Processed: 800000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:04:04,818] [INFO] Processed: 900000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:05:59,640] [INFO] Processed: 1000000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:08:31,991] [INFO] Processed: 1100000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:11:09,569] [INFO] Processed: 1200000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:14:23,893] [INFO] Processed: 1300000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:16:46,983] [INFO] Processed: 1400000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:17:54,394] [INFO] Processed: 1500000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:18:35,400] [INFO] Processed: 1600000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:19:17,591] [INFO] Processed: 1700000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:22:03,357] [INFO] Processed: 1800000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:24:11,432] [INFO] Processed: 1900000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:25:58,981] [INFO] Processed: 2000000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:27:22,147] [INFO] Processed: 2100000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:28:24,319] [INFO] Processed: 2200000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:29:43,279] [INFO] Processed: 2300000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:31:44,345] [INFO] Processed: 2400000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:33:29,157] [INFO] Processed: 2500000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:34:43,788] [INFO] Processed: 2600000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:36:54,992] [INFO] Processed: 2700000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:39:40,429] [INFO] Processed: 2800000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:41:31,143] [INFO] Processed: 2900000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:43:11,415] [INFO] Processed: 3000000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:45:02,334] [INFO] Processed: 3100000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:47:32,473] [INFO] Processed: 3200000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:50:21,355] [INFO] Processed: 3300000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:53:04,493] [INFO] Processed: 3400000 pages (_get_tasks@pool.py:528)\n",
            "[2022-10-31 20:53:19,494] [INFO] Starting to build a dictionary... (train@cli.py:133)\n",
            "[2022-10-31 20:53:19,537] [INFO] Step 1/2: Processing Wikipedia pages... (build_dictionary@cli.py:187)\n",
            "100% 2353747/2353747 [09:04<00:00, 4321.85it/s]\n",
            "[2022-10-31 21:02:24,177] [INFO] Step 2/2: Processing Wikipedia redirects... (build_dictionary@cli.py:187)\n",
            "[2022-10-31 21:02:55,590] [INFO] 669570 words and 573938 entities are indexed in the dictionary (build_dictionary@cli.py:187)\n",
            "[2022-10-31 21:02:55,807] [INFO] Starting to build a link graph... (train@cli.py:138)\n",
            "[2022-10-31 21:02:55,822] [INFO] Step 1/2: Processing Wikipedia pages... (build_link_graph@cli.py:200)\n",
            "100% 2353747/2353747 [00:58<00:00, 39969.58it/s]\n",
            "[2022-10-31 21:03:54,764] [INFO] Step 2/2: Converting matrix... (build_link_graph@cli.py:200)\n",
            "[2022-10-31 21:03:58,284] [INFO] Starting to build a mention DB... (train@cli.py:147)\n",
            "[2022-10-31 21:03:58,302] [INFO] Step 1/3: Starting to iterate over Wikipedia pages... (build_mention_db@cli.py:221)\n",
            "100% 2353747/2353747 [02:03<00:00, 19126.79it/s]\n",
            "[2022-10-31 21:06:01,409] [INFO] Step 2/3: Starting to count occurrences... (build_mention_db@cli.py:221)\n",
            "100% 2353747/2353747 [15:10<00:00, 2584.51it/s]\n",
            "[2022-10-31 21:21:13,834] [INFO] Step 3/3: Building DB... (build_mention_db@cli.py:221)\n",
            "[2022-10-31 21:21:22,944] [INFO] Starting to train embeddings... (train@cli.py:156)\n",
            "[2022-10-31 21:21:25,620] [INFO] Total number of word occurrences: 1333746350 (train_embedding@cli.py:257)\n",
            "[2022-10-31 21:21:25,620] [INFO] Building a sampling table for frequent words... (train_embedding@cli.py:257)\n",
            "[2022-10-31 21:21:26,646] [INFO] Building tables for negative sampling... (train_embedding@cli.py:257)\n",
            "[2022-10-31 21:21:44,842] [INFO] Building tables for link indices... (train_embedding@cli.py:257)\n",
            "[2022-10-31 21:22:13,698] [INFO] Starting to train embeddings... (train_embedding@cli.py:257)\n",
            "[2022-10-31 21:22:13,975] [INFO] Initializing weights... (train_embedding@cli.py:257)\n",
            "Iteration 1/5: 100% 2353747/2353747 [1:10:52<00:00, 553.52it/s]\n",
            "Iteration 2/5: 100% 2353747/2353747 [1:10:35<00:00, 555.69it/s]\n",
            "Iteration 3/5: 100% 2353747/2353747 [1:10:31<00:00, 556.22it/s]\n",
            "Iteration 4/5: 100% 2353747/2353747 [1:10:09<00:00, 559.20it/s]\n",
            "Iteration 5/5: 100% 2353747/2353747 [1:10:03<00:00, 559.92it/s]\n",
            "[2022-11-01 03:14:33,180] [INFO] Terminating pool workers... (train_embedding@cli.py:257)\n"
          ]
        }
      ],
      "source": [
        "!wikipedia2vec train arwiki-20220801-pages-articles-multistream.xml.bz2 ARWIKI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXoiHNPc9eO_"
      },
      "source": [
        "## Exporting Arabic Wikipedia Word Vectors in GloVe Format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLjVhVDq9iFL"
      },
      "outputs": [],
      "source": [
        "! wikipedia2vec save-text ARWIKI GloVe-AR-Vectors.txt --out-format glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QESbVNxg_qNZ"
      },
      "outputs": [],
      "source": [
        "! wikipedia2vec save-text ARWIKI Word2Vec-AR-Vectors.txt --out-format word2vec "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnDNs5ip9w5i"
      },
      "source": [
        "## Saving Arabic Wikipedia Word Vectors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "Dv9J1bm993Pr",
        "outputId": "cc0d9f02-ca2b-4757-aa1a-f286df4747f2"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_560aca77-2f1d-42bf-8b8f-85ec5793d48d\", \"ARWIKI\", 1014687897)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_478a8767-2075-4592-bf17-1c47bc32e1e3\", \"GloVe-AR-Vectors.txt\", 972377130)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_b35aafb8-a461-42de-8002-808dc04a8ae8\", \"Word2Vec-AR-Vectors.txt\", 972377142)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('ARWIKI')\n",
        "files.download('GloVe-AR-Vectors.txt')\n",
        "files.download('Word2Vec-AR-Vectors.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nEmQAta-d-0"
      },
      "source": [
        "## GloVe Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czS22gOM-fdp"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "import warnings, os\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
        "\n",
        "glove_file = datapath('/content/GloVe-AR-Vectors.txt')\n",
        "word2vec_glove_file = get_tmpfile(\"glove-ar-vectors-word2vec.txt\")\n",
        "glove2word2vec(glove_file, word2vec_glove_file)\n",
        "\n",
        "glove_model = KeyedVectors.load_word2vec_format(word2vec_glove_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT16ZbWdHW8b"
      },
      "source": [
        "## Word2Vec Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PUANu5fx9olY"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "word2vec_model = KeyedVectors.load_word2vec_format('/content/Word2Vec-AR-Vectors.txt', binary=False) #without *norm_only* param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7O3-IlhKWZ0",
        "outputId": "217bff1b-72eb-4e02-83b8-38651713927e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1243508 100\n",
            "في -0.0448 -0.0666 0.0066 0.2682 -0.0428 -0.1809 0.1323 0.1813 -0.5969 -0.1857 -0.0559 -0.1572 -0.3836 -0.3517 -0.1806 0.1182 0.2896 0.2042 -0.3244 -0.0408 0.1691 -0.1902 0.5418 0.0304 0.1718 0.4459 -0.0734 0.0129 0.4128 -0.7096 0.0173 0.3136 0.0523 -0.4479 -0.3223 -0.0521 -0.0182 0.3708 -0.3598 0.0547 -0.1831 0.5196 -0.1552 -0.3890 -0.5623 -0.3929 0.0159 0.2491 0.4086 0.0996 -0.2957 -0.0748 0.2286 0.3034 0.1353 0.3469 -0.1571 0.2121 -0.1312 0.1828 0.2772 -0.0594 0.3157 0.0430 0.1583 -0.2102 0.3700 -0.4715 -0.0396 0.0901 0.4905 0.5190 0.0924 0.0043 -0.3297 -0.1939 0.4425 -0.4682 0.0221 0.2124 0.1197 0.1573 0.4267 -0.1313 0.1513 -0.4229 0.2716 -0.0103 -0.0991 0.1641 -0.3074 0.0426 -0.1102 0.2237 0.0655 0.0226 -0.2184 -0.3177 0.1354 0.2755\n",
            "تصنيف 0.4063 -0.7124 0.2448 0.2921 -0.4781 0.6271 0.6030 0.2339 -0.8716 -0.4246 0.2578 0.0806 -0.3691 -0.4853 -0.8610 -0.8275 0.7191 -0.0644 0.5859 -0.0928 -0.2533 -0.7386 1.0200 -0.6077 -0.1359 -0.1922 -0.2171 0.8029 1.3978 -1.6333 0.2076 1.2030 -0.2755 -1.2085 -1.3109 -0.0477 0.1511 0.3959 -1.3864 -0.0091 -0.6218 -0.3628 0.5714 -0.6628 -0.3635 -0.6609 0.4827 0.0365 -0.0442 -0.7578 -0.2921 0.1136 0.2892 0.7813 -0.4573 0.0857 -0.1698 0.5104 0.5198 1.0194 -0.0132 0.5256 0.3898 0.2791 0.3342 -0.6464 0.2541 -2.0742 -0.0714 -0.0704 0.6928 0.9315 0.5923 -0.4492 0.0875 -0.0606 -0.0304 -0.7783 -0.1088 0.7049 -0.1117 -0.1029 0.3009 -0.6591 0.9131 0.0622 0.4392 -0.4022 0.3868 -0.0899 1.0598 0.1565 -1.4136 -1.2413 1.1218 0.4985 -0.2399 -0.1031 0.2493 0.6455\n"
          ]
        }
      ],
      "source": [
        "!head -3 Word2Vec-AR-Vectors.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2kDIK60KiEO",
        "outputId": "61983a3d-2633-4425-da27-6f1af3edb376"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "في -0.0448 -0.0666 0.0066 0.2682 -0.0428 -0.1809 0.1323 0.1813 -0.5969 -0.1857 -0.0559 -0.1572 -0.3836 -0.3517 -0.1806 0.1182 0.2896 0.2042 -0.3244 -0.0408 0.1691 -0.1902 0.5418 0.0304 0.1718 0.4459 -0.0734 0.0129 0.4128 -0.7096 0.0173 0.3136 0.0523 -0.4479 -0.3223 -0.0521 -0.0182 0.3708 -0.3598 0.0547 -0.1831 0.5196 -0.1552 -0.3890 -0.5623 -0.3929 0.0159 0.2491 0.4086 0.0996 -0.2957 -0.0748 0.2286 0.3034 0.1353 0.3469 -0.1571 0.2121 -0.1312 0.1828 0.2772 -0.0594 0.3157 0.0430 0.1583 -0.2102 0.3700 -0.4715 -0.0396 0.0901 0.4905 0.5190 0.0924 0.0043 -0.3297 -0.1939 0.4425 -0.4682 0.0221 0.2124 0.1197 0.1573 0.4267 -0.1313 0.1513 -0.4229 0.2716 -0.0103 -0.0991 0.1641 -0.3074 0.0426 -0.1102 0.2237 0.0655 0.0226 -0.2184 -0.3177 0.1354 0.2755\n",
            "تصنيف 0.4063 -0.7124 0.2448 0.2921 -0.4781 0.6271 0.6030 0.2339 -0.8716 -0.4246 0.2578 0.0806 -0.3691 -0.4853 -0.8610 -0.8275 0.7191 -0.0644 0.5859 -0.0928 -0.2533 -0.7386 1.0200 -0.6077 -0.1359 -0.1922 -0.2171 0.8029 1.3978 -1.6333 0.2076 1.2030 -0.2755 -1.2085 -1.3109 -0.0477 0.1511 0.3959 -1.3864 -0.0091 -0.6218 -0.3628 0.5714 -0.6628 -0.3635 -0.6609 0.4827 0.0365 -0.0442 -0.7578 -0.2921 0.1136 0.2892 0.7813 -0.4573 0.0857 -0.1698 0.5104 0.5198 1.0194 -0.0132 0.5256 0.3898 0.2791 0.3342 -0.6464 0.2541 -2.0742 -0.0714 -0.0704 0.6928 0.9315 0.5923 -0.4492 0.0875 -0.0606 -0.0304 -0.7783 -0.1088 0.7049 -0.1117 -0.1029 0.3009 -0.6591 0.9131 0.0622 0.4392 -0.4022 0.3868 -0.0899 1.0598 0.1565 -1.4136 -1.2413 1.1218 0.4985 -0.2399 -0.1031 0.2493 0.6455\n",
            "من -0.2491 -0.2395 0.4378 0.2624 -0.2521 -0.3339 0.1605 0.3718 -0.8522 -0.0650 0.0636 0.1325 -0.2231 -0.2285 -0.1319 0.2257 0.2307 -0.0775 -0.6815 -0.1984 0.0252 -0.4509 0.8941 0.4045 0.2909 0.2853 -0.0762 0.3626 0.1039 -0.1675 0.2009 0.5080 0.1987 -0.0573 -0.2494 -0.1367 0.0051 0.3330 -0.2236 0.5011 0.3376 0.2874 -0.2889 -0.5135 -0.3349 -0.3040 0.2647 0.2650 0.2797 -0.1118 -0.3461 -0.0005 0.2321 -0.1365 0.2158 0.2807 -0.2473 0.3629 -0.2996 0.1808 -0.0758 -0.1027 0.0086 0.0397 -0.1500 -0.1552 -0.0448 -0.2346 0.1857 0.0675 -0.1935 0.4919 -0.1234 -0.1569 -0.6792 -0.2014 0.3186 -0.5437 0.0558 0.0023 0.0334 -0.0534 0.1459 0.0632 0.2244 -0.0336 -0.0168 0.3682 -0.1905 -0.1273 -0.1947 0.3592 -0.1249 0.0154 0.0776 0.1109 -0.0964 -0.1241 0.1940 0.2846\n",
            "هو -0.0105 0.0703 0.2471 0.8032 -0.2703 -0.0572 -0.2867 0.3019 -0.5750 -0.2088 -0.0037 0.1668 0.1089 -0.4066 0.1288 0.2953 -0.2313 -0.2172 -0.2843 -0.4138 0.5361 -0.4075 0.7246 -0.4270 0.5637 0.4245 -0.0727 -0.1586 0.1138 -0.3498 -0.2304 0.3443 0.3282 0.1074 -0.7461 -0.7445 0.3136 0.1713 -0.1250 0.3186 -0.0372 0.1065 -0.1787 -0.3223 -0.2733 0.0464 0.1327 -0.0177 0.4461 -0.1379 -0.2416 0.0099 -0.0020 0.0192 0.1438 0.5825 -0.0271 0.3639 0.0621 0.1639 0.2497 0.3228 -0.0178 0.3092 0.4368 0.2448 0.7311 -0.2542 0.1528 -0.2615 -0.1920 -0.0646 0.1153 0.0910 -0.4791 -0.2535 0.9969 -0.4060 -0.1463 0.1468 -0.2815 -0.0456 0.2420 -0.1269 0.3384 -0.5664 -0.1857 -0.0769 -0.4638 0.5229 -0.4954 -0.1897 0.0335 -0.4426 -0.1043 -0.4729 0.2085 -0.1349 0.2655 0.3031\n",
            "حسب 0.4979 0.1121 -0.5112 -0.3257 -0.2126 0.1662 0.5421 -0.1037 -0.5494 -0.7126 0.4676 0.0654 -0.3109 -0.4314 -0.2966 -0.2965 0.3647 0.3042 0.7816 -0.6303 0.5572 0.2527 1.0232 0.2815 -0.0333 0.3308 0.0494 -0.2266 1.7999 -1.1281 0.4864 0.5847 0.1734 0.1277 -0.3245 0.1682 0.7644 -0.1093 -0.1362 -0.6309 -0.4010 0.1204 -0.2229 -0.9365 -0.3461 -0.7957 -0.3836 0.0266 0.1532 -0.1175 0.3131 0.0542 0.1481 0.4389 -0.7080 0.2540 0.0562 1.0118 -0.1092 0.6759 0.9480 0.6572 -0.7611 0.6859 0.1852 -0.9592 1.3416 -0.4270 -0.0553 -0.4161 1.0623 1.0480 -0.4933 0.3286 -0.4399 -0.5023 0.2691 -0.9983 0.0700 0.5337 -0.0639 0.6086 0.3555 -0.5574 0.5721 -0.2577 -0.1900 0.0292 0.1332 -0.0329 0.7327 0.0699 0.0485 -0.7521 0.1232 1.0656 -0.0118 -0.2918 0.2168 0.6804\n",
            "على -0.3163 -0.1748 0.0891 0.0770 -0.1429 -0.2856 -0.1197 0.2636 -0.6106 -0.1394 -0.1150 -0.1888 0.1186 -0.4255 -0.0983 -0.3383 0.0705 0.0480 -0.3111 -0.5579 -0.0094 -0.4161 0.7483 0.3040 -0.3088 0.3789 -0.2538 0.2291 0.2850 -0.2318 -0.3111 0.4193 0.5439 -0.2686 -0.3927 -0.1391 0.0537 -0.0062 -0.3515 0.1212 -0.6286 0.1769 -0.0394 -0.5441 -0.4200 -0.1196 0.5691 0.2824 0.1542 0.2493 -0.1174 -0.2263 0.0755 0.1812 -0.1749 -0.0632 0.0401 0.1210 -0.0162 0.0280 0.1271 -0.1303 0.4966 -0.2240 -0.0012 -0.4452 0.3026 -0.2860 0.1499 0.2328 -0.1420 0.1524 -0.0033 0.1498 -0.1217 -0.7715 0.7010 -0.5170 0.4271 -0.0919 -0.1554 0.0526 0.1026 0.2361 0.5183 -0.0084 0.2604 0.4193 -0.2620 -0.1966 0.0068 0.1201 -0.2537 0.2861 -0.0322 0.2060 -0.0497 0.0316 -0.1628 0.3737\n",
            "هي -0.0420 0.3750 0.4918 0.3676 -0.2974 0.1844 -0.3500 0.5986 -0.8117 0.1092 -0.5307 -0.0748 0.0310 -0.4179 -0.0166 0.1745 -0.2054 -0.9209 -0.3569 -0.2547 0.1317 -0.0468 0.5329 -0.3417 0.0399 0.3206 -0.3671 -0.1059 0.0719 -0.5655 0.0092 0.8430 0.0886 -0.4758 -0.4676 -0.4515 0.2504 0.2999 -0.0387 0.0082 0.0284 0.0805 -0.2495 -0.4618 -0.0591 -0.0507 0.0384 0.4290 0.3922 -0.1601 -0.2030 -0.0634 0.0228 -0.3295 -0.2331 0.4874 0.0534 0.0456 0.1645 -0.0817 0.4343 0.1991 -0.6397 0.4488 -0.0212 -0.1238 0.0999 -0.2104 0.4266 -0.2473 0.0989 0.3142 0.2003 -0.1067 -0.1588 -0.5887 0.7929 -0.2156 -0.0301 0.2960 0.2745 -0.2428 0.1834 -0.3141 0.0391 -0.5330 0.8878 -0.1190 0.1079 0.4052 -0.0343 -0.0932 -0.3369 -0.1436 0.3849 0.1547 -0.0969 0.0451 -0.0089 -0.0981\n",
            "المتحدة 0.2546 0.4874 0.8781 1.0492 0.1822 0.3951 0.0130 0.1353 -0.6345 0.1387 0.0266 -0.4167 -0.7584 -0.4117 0.5477 0.1200 0.4388 0.6586 -0.1964 -0.6997 0.2444 -0.6507 0.1939 0.3567 0.1562 0.5710 0.0492 0.4786 0.7265 0.0830 -0.1899 0.4880 -0.4393 -0.3826 -0.6286 -0.1787 0.1484 0.4347 -0.2984 -0.2079 -0.2347 0.7479 -0.3736 -0.2969 -0.6222 -0.2239 0.0419 0.0374 0.7851 0.4587 -0.2866 0.1951 0.3259 0.1945 0.3697 -0.3236 0.2193 -0.3403 -0.5218 0.8223 0.1548 -0.2228 0.2004 0.8083 0.0275 0.1775 0.6225 -0.3547 -0.1913 -0.3166 0.9059 0.4226 0.0583 0.9175 0.1359 -0.1648 0.3627 -1.0532 -0.1211 0.4756 -0.0380 0.5521 0.8022 -0.1831 -0.4728 -0.8024 0.4791 -0.5503 0.6865 -0.1063 0.1850 0.1070 -0.1033 -0.4277 -0.2719 0.0044 -0.0114 -0.2142 0.6245 0.0215\n",
            "إلى -0.3978 0.0553 0.2199 0.2337 -0.2661 -0.2838 0.2914 -0.0969 -0.2924 -0.0515 0.0958 -0.3457 0.2544 -0.0111 -0.0349 0.1602 0.0418 -0.2964 -0.1526 -0.0412 0.1691 -0.2050 0.4385 0.2140 0.0127 0.3717 0.0179 -0.0979 0.5758 -0.0470 0.0016 0.4040 -0.1943 0.0271 -0.0882 0.0011 -0.2358 0.1336 -0.2564 0.3594 0.1605 0.2769 0.0047 -0.5727 -0.9801 -0.3024 0.2319 0.3792 0.4084 -0.0122 -0.4073 -0.5867 0.2247 -0.0201 -0.1851 0.2774 -0.2350 0.4484 -0.3235 0.0723 0.2921 -0.0970 0.0413 0.3166 0.0361 0.2353 0.0880 -0.9954 -0.2346 0.0285 0.2089 0.5293 0.2561 0.4245 -0.3064 -0.3840 0.3401 -0.4042 0.1794 -0.2195 0.1206 0.3288 0.6276 -0.0738 -0.0808 -0.1182 0.2100 0.2592 -0.2954 -0.2748 -0.0584 0.4148 -0.1670 -0.0602 -0.1135 -0.1514 -0.0246 -0.1054 -0.1109 0.5695\n",
            "القرن 0.9417 -0.8213 -0.0104 0.3234 -0.8315 -0.3554 0.3421 0.1500 -0.1445 -0.4328 -0.2069 -1.1382 -0.7730 -0.7834 -0.0935 -0.0673 0.8498 0.3018 0.4673 0.1439 1.4587 -0.9645 1.1034 0.3311 0.0840 0.0651 -0.2232 0.7154 0.0341 -0.6434 0.1065 1.1213 -0.2559 -0.9237 -0.0930 0.2041 0.0167 0.5806 -0.0939 -0.6949 0.3283 0.8596 0.4081 0.1834 -0.6594 -0.2589 0.0459 0.6422 0.2853 -0.5004 -0.1197 -0.6520 0.6076 0.5009 -0.1744 -0.6145 -1.0051 0.8752 0.1174 0.3622 0.4453 0.1079 -0.1097 -0.1405 0.6237 -0.1595 0.8889 -0.2748 0.5160 0.1500 0.5553 -0.4104 0.5914 -0.9768 -1.1504 0.0010 0.0271 -0.1800 0.1312 -0.0908 0.6274 0.3244 0.4855 -0.2538 0.1066 0.1788 -0.0892 0.2418 -0.0837 0.4363 0.3320 0.1234 -0.3699 0.8364 0.7777 -0.0106 -0.0233 -0.0615 0.7301 -0.0236\n"
          ]
        }
      ],
      "source": [
        "!head GloVe-AR-Vectors.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSfzrevT-u7K"
      },
      "source": [
        "### Word Embeddings of a Given Word:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3Na-4ey-yla",
        "outputId": "093b747c-5066-4f54-aefe-e3ed4d036730"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0182,  0.1268,  0.0323, -0.2797, -0.2255,  0.141 ,  0.3945,\n",
              "        0.1535, -0.3708, -0.2556,  0.2525,  0.5507, -0.6943, -0.4315,\n",
              "        0.4081,  1.2582,  0.413 , -0.9997, -0.5266, -0.5232,  0.1388,\n",
              "        0.3177,  0.0104,  0.372 , -0.2198, -0.0683, -0.5126, -0.0418,\n",
              "       -0.308 , -0.1393, -0.1664,  0.3687, -0.609 , -0.442 , -0.5158,\n",
              "       -0.0988,  0.5252,  0.6538, -0.1124,  0.4461,  0.0947,  0.2856,\n",
              "       -0.2991,  0.2409, -0.8765, -0.3864,  0.0955,  0.4459,  0.144 ,\n",
              "        0.0126,  0.2636,  0.2331,  0.322 ,  0.0244, -0.3738, -0.6066,\n",
              "       -0.1775,  0.3868,  0.4536, -0.0989,  0.4599, -0.2481,  0.2161,\n",
              "        0.1738, -0.1589, -0.2373, -0.3509, -0.1993,  0.1173, -0.3738,\n",
              "        0.8868, -0.1698, -0.1047,  0.2931, -0.1791, -0.7831,  0.2652,\n",
              "       -0.6006, -0.0037,  0.178 , -0.0557,  0.2259,  0.0682,  0.2794,\n",
              "       -0.3161, -0.1228,  0.5555,  0.6845, -0.3556, -0.423 , -0.2913,\n",
              "       -0.0678, -0.5005,  0.044 , -0.046 ,  0.1741,  0.1946,  0.3935,\n",
              "       -0.0061,  0.0033], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "word2vec_model['فتاة']  # Word is girl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoySPjc1-6SY"
      },
      "source": [
        "### Glove's Most Similar Words of a Given word:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2dZty9t-8UY",
        "outputId": "ddddc9c4-1ce7-4363-c19b-c8499362b06e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('طفلة', 0.8759556412696838),\n",
              " ('شابة', 0.8365658521652222),\n",
              " ('فتاه', 0.8252592086791992),\n",
              " ('وفتاة', 0.8144962787628174),\n",
              " ('لفتاة', 0.8021165132522583),\n",
              " ('كفتاة', 0.7916913032531738),\n",
              " ('إمراة', 0.7868704795837402),\n",
              " ('تلميذة', 0.7831072807312012),\n",
              " ('بفتاة', 0.7809919118881226),\n",
              " ('مدللة', 0.7773781418800354)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "word2vec_model.most_similar(\"فتاة\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPINUtuJ_Ezh"
      },
      "source": [
        "## Word Embedding Analogies Testing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1iUHnk3_S0C"
      },
      "source": [
        "### Queen - Woman + Man = ____?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41mvPbMO_Wo_",
        "outputId": "59b5f6ea-de86-4251-8cb7-4fea2bdbf266"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ملك', 0.6721993684768677)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "word2vec_model.most_similar(positive=['رجل', 'ملكة'], negative=['امرأة'], topn=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f87j7rlY_9jm"
      },
      "source": [
        "### King - Man + Woman =___?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FOAYAxIABX2",
        "outputId": "0591cd92-8380-4a74-9802-91341743010a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ملكة', 0.6481277346611023)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "word2vec_model.most_similar(positive=['إمرأة','ملك'], negative=['رجل'], topn=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9QUxDlqDDBG"
      },
      "source": [
        "### Son is to Man AS Woman is to ___?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_q3fTv6TBvFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7d0002-c1b9-4255-b03c-886bc7ccaea2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('امرأة', 0.7423989772796631),\n",
              " ('إمراة', 0.6593736410140991),\n",
              " ('مرأة', 0.6542191505432129),\n",
              " ('أمرأة', 0.6446183919906616),\n",
              " ('امراة', 0.6393841505050659),\n",
              " ('عجوز', 0.6130526661872864),\n",
              " ('وشابة', 0.6081492900848389),\n",
              " ('أمراة', 0.607975423336029),\n",
              " ('امرأءة', 0.5910994410514832),\n",
              " ('وامرأة', 0.589683473110199)]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "word2vec_model.most_similar(positive=['إمرأة','رجل'], negative=['ابن']) #7th is `girl` but not `daughter`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VaOp4MvGCaU"
      },
      "source": [
        "### Bad is to Worst AS  Good is to ___?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QmaqQbXtGuDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8981b7-123b-435c-b1dd-81f4dc958146"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('أفضل', 0.7800378203392029)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "word2vec_model.most_similar(positive=['أسوأ','جيد'], negative=['سيء'], topn=1)   # result is better"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### United States is to Washington AS Saudi Arabia is to ___?"
      ],
      "metadata": {
        "id": "tZvCbKKQYalk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model.most_similar(positive=['السعودية','واشنطن'], negative=['امريكا'], topn=1) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln_7-AndWoB3",
        "outputId": "e2667eb5-6cc4-4883-c72a-befb80ba086d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('الرياض', 0.6407883167266846)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaDv8LKhAVo7"
      },
      "source": [
        "### Using The list of Arabic Words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U47hXFs4Ah8x",
        "outputId": "ef64849f-6214-4edd-ddcf-967a922e8cb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "امرأه >>>>> [('امراة', 0.8110108375549316)] \n",
            "\n",
            "رجل >>>>> [('ورجل', 0.8235027194023132)] \n",
            "\n",
            "ابن >>>>> [('وابن', 0.8918744325637817)] \n",
            "\n",
            "أم >>>>> [('ام', 0.6912806630134583)] \n",
            "\n",
            "أب >>>>> [('وأب', 0.7017418146133423)] \n",
            "\n",
            "فتاة >>>>> [('طفلة', 0.8759556412696838)] \n",
            "\n",
            "فتى >>>>> [('صبي', 0.8588953018188477)] \n",
            "\n",
            "ملكة >>>>> [('وملكة', 0.8994596004486084)] \n",
            "\n",
            "ملك >>>>> [('وملك', 0.8720160126686096)] \n",
            "\n",
            "سيدة >>>>> [('وسيدة', 0.812030553817749)] \n",
            "\n",
            "سيد >>>>> [('وسيد', 0.8042435646057129)] \n",
            "\n",
            "ابنة >>>>> [('حفيدة', 0.9387456178665161)] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "words= ['امرأه','رجل','ابن','أم','أب','فتاة','فتى','ملكة','ملك','سيدة','سيد','ابنة'] #  formal list is  [daughter,sir,madam,king,queen,boy,girl,father,mother,son,man,woman] respectively.\n",
        "for w in words:\n",
        "   print(w ,\">>>>>\" , word2vec_model.most_similar(w, topn=1) ,\"\\n\")  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyN911OxSUBwF35M1FlG7x7f",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}